{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim, cuda\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "import load_data\n",
    "from load_data import ForamDataSet\n",
    "from importlib import reload\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on gpu: False\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "save_file_name = 'vgg16-transfer-4.pt'\n",
    "checkpoint_path = 'vgg16-transfer-4.pth'\n",
    "\n",
    "# Whether to train on a gpu\n",
    "train_on_gpu = cuda.is_available()\n",
    "print('Train on gpu: {train_on_gpu}'.format(train_on_gpu=train_on_gpu))\n",
    "multi_gpu = False\n",
    "# Number of gpus\n",
    "if train_on_gpu:\n",
    "    gpu_count = cuda.device_count()\n",
    "    print('{gpu_count} gpus detected.'.format(gpu_count=gpu_count))\n",
    "    if gpu_count > 1:\n",
    "        multi_gpu = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    # val does not use augmentation\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    # test does not use augmentation\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../media'\n",
    "image_datasets = {}\n",
    "image_datasets['train'] = ForamDataSet(csv_file='../train.csv',\n",
    "                                       root_dir='../media',\n",
    "                                       transform=data_transforms['train'])\n",
    "image_datasets['val'] = ForamDataSet(csv_file='../val.csv',\n",
    "                                     root_dir='../media',\n",
    "                                     transform=data_transforms['val'])\n",
    "image_datasets['test'] = ForamDataSet(csv_file='../test.csv',\n",
    "                                     root_dir='../media',\n",
    "                                     transform=data_transforms['test'])                                     \n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "classes = image_datasets['train'].labels\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(path):\n",
    "    \"\"\"Load a PyTorch model checkpoint\n",
    "\n",
    "    Params\n",
    "    --------\n",
    "        path (str): saved model checkpoint. Must start with `model_name-` and end in '.pth'\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "        None, save the `model` to `path`\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the model name\n",
    "    model_name = path.split('-')[0]\n",
    "\n",
    "    # Load in checkpoint\n",
    "    checkpoint = torch.load(path, map_location='cpu')\n",
    "\n",
    "    if model_name == 'vgg16':\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        # Make sure to set parameters as not trainable\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        model.classifier = checkpoint['classifier']\n",
    "\n",
    "    elif model_name == 'resnet50':\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        # Make sure to set parameters as not trainable\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        model.fc = checkpoint['fc']\n",
    "\n",
    "    # Load in the state dict\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "    # Move to gpu\n",
    "    if multi_gpu:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    if train_on_gpu:\n",
    "        model = model.to('cuda')\n",
    "\n",
    "    # Model basics\n",
    "    model.idx_to_class = checkpoint['idx_to_class']\n",
    "    model.epochs = checkpoint['epochs']\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = checkpoint['optimizer']\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer = load_checkpoint('vgg16-transfer-4.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
      "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
      "              ReLU-7        [-1, 128, 112, 112]               0\n",
      "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
      "              ReLU-9        [-1, 128, 112, 112]               0\n",
      "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
      "             ReLU-12          [-1, 256, 56, 56]               0\n",
      "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-14          [-1, 256, 56, 56]               0\n",
      "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-16          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-17          [-1, 256, 28, 28]               0\n",
      "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
      "             ReLU-19          [-1, 512, 28, 28]               0\n",
      "           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-21          [-1, 512, 28, 28]               0\n",
      "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-23          [-1, 512, 28, 28]               0\n",
      "        MaxPool2d-24          [-1, 512, 14, 14]               0\n",
      "           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-26          [-1, 512, 14, 14]               0\n",
      "           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-28          [-1, 512, 14, 14]               0\n",
      "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-30          [-1, 512, 14, 14]               0\n",
      "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
      "           Linear-32                 [-1, 4096]     102,764,544\n",
      "             ReLU-33                 [-1, 4096]               0\n",
      "          Dropout-34                 [-1, 4096]               0\n",
      "           Linear-35                 [-1, 4096]      16,781,312\n",
      "             ReLU-36                 [-1, 4096]               0\n",
      "          Dropout-37                 [-1, 4096]               0\n",
      "           Linear-38                  [-1, 256]       1,048,832\n",
      "             ReLU-39                  [-1, 256]               0\n",
      "          Dropout-40                  [-1, 256]               0\n",
      "           Linear-41                   [-1, 17]           4,369\n",
      "       LogSoftmax-42                   [-1, 17]               0\n",
      "================================================================\n",
      "Total params: 135,313,745\n",
      "Trainable params: 1,053,201\n",
      "Non-trainable params: 134,260,544\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 218.59\n",
      "Params size (MB): 516.18\n",
      "Estimated Total Size (MB): 735.34\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1, )):\n",
    "    \"\"\"\n",
    "    Compute the topk accuracy(s)\n",
    "    target: the correct answer\n",
    "    \"\"\"\n",
    "    if train_on_gpu:\n",
    "        output = output.to('cuda')\n",
    "        target = target.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        # Find the predicted classes and transpose\n",
    "        _, pred = output.topk(k=maxk, dim=1, largest=True, sorted=True)\n",
    "        pred = pred.t()\n",
    "        # Determine predictions equal to the targets\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "        res = []\n",
    "\n",
    "        # For each k, find the percentage of correct\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size).item())\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_for_categories(model, test_loader, criterion, topk=(1, 5)):\n",
    "    \"\"\"Measure the performance of a trained PyTorch model\n",
    "\n",
    "    Params\n",
    "    --------\n",
    "        model (PyTorch model): trained cnn for inference\n",
    "        test_loader (PyTorch DataLoader): test dataloader\n",
    "        topk (tuple of ints): accuracy to measure\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "        results (DataFrame): results for each category\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    classes = []\n",
    "    losses = []\n",
    "    # Hold accuracy results\n",
    "    acc_results = np.zeros((len(test_loader.dataset), len(topk)))\n",
    "    i = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Testing loop\n",
    "        for data, targets in test_loader:\n",
    "\n",
    "            # Tensors to gpu\n",
    "            if train_on_gpu:\n",
    "                data, targets = data.to('cuda'), targets.to('cuda')\n",
    "\n",
    "            # Raw model output\n",
    "            out = model(data)\n",
    "            # Iterate through each example\n",
    "            for pred, true in zip(out, targets):\n",
    "                # Find topk accuracy\n",
    "                acc_results[i, :] = accuracy(\n",
    "                    pred.unsqueeze(0), true.unsqueeze(0), topk)\n",
    "                classes.append(model.idx_to_class[true.item()])\n",
    "                # Calculate the loss\n",
    "                loss = criterion(pred.view(1, 17), true.view(1))\n",
    "                losses.append(loss.item())\n",
    "                i += 1\n",
    "\n",
    "    # Send results to a dataframe and calculate average across classes\n",
    "    for i in topk:\n",
    "        results = pd.DataFrame(acc_results, columns=['top{i}'.format(i=i) for i in topk])\n",
    "        results['class'] = classes\n",
    "        results['loss'] = losses\n",
    "        results = results.groupby(classes).mean()\n",
    "\n",
    "    return results.reset_index().rename(columns={'index': 'class'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "results = evaluate_for_categories(model, dataloaders['test'], criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  class       top1        top5      loss\n",
      "0       G. crassaformis   0.000000   69.230769  2.975598\n",
      "1          G. elongatus  42.857143   95.238095  1.294481\n",
      "2              G. ruber  80.000000   94.285714  0.929556\n",
      "3         G. ruber pink   0.000000  100.000000  2.023419\n",
      "4         G. sacculifer  92.105263  100.000000  0.425107\n",
      "5            G. scitula  53.333333   86.666667  1.645150\n",
      "6        G. siphonifera  74.285714   91.428571  0.942716\n",
      "7   G. truncatulinoides  79.069767   93.023256  0.969238\n",
      "8             G. tumida  80.000000   97.142857  0.657629\n",
      "9           G. ungulata  78.947368   94.736842  0.812657\n",
      "10       N. acostaensis  52.380952   90.476190  1.907194\n",
      "11         N. dutertrei  78.571429  100.000000  0.747720\n",
      "12          N. humerosa  64.000000   88.000000  1.599275\n",
      "13          O. universa  60.000000  100.000000  0.408932\n",
      "14   P. obliquiloculata  54.285714   97.142857  1.096761\n",
      "15          S. dehiscen  80.555556   97.222222  0.749842\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1(model, test_loader):\n",
    "    '''\n",
    "    class_info = {class_index: [true_postiive,\n",
    "                                false_positive,\n",
    "                                total_per_species,\n",
    "                                precision,\n",
    "                                recall,\n",
    "                                F-score]}\n",
    "    '''\n",
    "    model.eval()\n",
    "    class_info = {}\n",
    "    for i in range(len(image_datasets['train'].labels)):\n",
    "        class_info[i] = [0,0,0]\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            # Tensors to gpu\n",
    "            if train_on_gpu:\n",
    "                data, targets = data.to('cuda'), targets.to('cuda')\n",
    "                # Raw model output\n",
    "            out = model(data)\n",
    "            _, pred = out.topk(k=1, dim=1, largest=True, sorted=True)\n",
    "            pred = torch.squeeze(pred, 1)\n",
    "            for i in range(len(targets)):\n",
    "                if pred[i] == targets[i]: # prediction correct, add to true positive\n",
    "                    temp = class_info[int(pred[i])]\n",
    "                    temp[0] = temp[0] + 1\n",
    "                    class_info[int(pred[i])] = temp\n",
    "                else: # prediction wrong, add to false positive\n",
    "                    temp = class_info[int(pred[i])]\n",
    "                    temp[1] = temp[1] + 1\n",
    "                    class_info[int(pred[i])] = temp\n",
    "    test_csv = pd.read_csv('../test.csv').groupby('species').count()\n",
    "    species = image_datasets['train'].labels\n",
    "    print(class_info)\n",
    "    for i in range(test_csv.shape[0]):\n",
    "        row = test_csv.iloc[i]\n",
    "        print(row)\n",
    "        arr = class_info[species.index(row.name)]\n",
    "        if arr == [0,0,0]:\n",
    "            continue\n",
    "        print(arr)\n",
    "        arr[2] = int(row.location)\n",
    "        arr.append(arr[0]/(arr[0]+arr[1]))\n",
    "        arr.append(arr[0]/arr[2])\n",
    "        try:\n",
    "            arr.append((2*arr[3]*arr[4])/(arr[3]+arr[4]))\n",
    "        except ZeroDivisionError:\n",
    "            arr.append(float('nan'))\n",
    "        class_info[species.index(row.name)] = arr\n",
    "    total_true_positives = 0\n",
    "    total_false_postives = 0\n",
    "    total = 0\n",
    "    for key,values in class_info.items():\n",
    "        total_true_positives += values[0]\n",
    "        total_false_postives += values[1]\n",
    "        total += values[2]\n",
    "    micro_avg_prec = total_true_positives/(total_true_positives+total_false_postives)\n",
    "    micro_avg_rec = total_true_positives/total\n",
    "    micro_f1 = (2*micro_avg_prec*micro_avg_rec)/(micro_avg_prec+micro_avg_rec)\n",
    "    df = pd.DataFrame.from_dict(class_info, orient='index',\n",
    "                        columns=['true_positive','false_positive','total_per_species','precision','recall','F-score'])\n",
    "    return micro_f1, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [0, 1, 0], 1: [9, 1, 0], 2: [0, 0, 0], 3: [28, 14, 0], 4: [0, 0, 0], 5: [35, 22, 0], 6: [16, 4, 0], 7: [26, 5, 0], 8: [34, 44, 0], 9: [28, 1, 0], 10: [15, 4, 0], 11: [11, 5, 0], 12: [11, 13, 0], 13: [16, 6, 0], 14: [3, 3, 0], 15: [19, 9, 0], 16: [29, 9, 0]}\n",
      "location    26\n",
      "Name: G. crassaformis, dtype: int64\n",
      "[0, 1, 0]\n",
      "location    21\n",
      "Name: G. elongatus, dtype: int64\n",
      "[9, 1, 0]\n",
      "location    35\n",
      "Name: G. ruber, dtype: int64\n",
      "[28, 14, 0]\n",
      "location    3\n",
      "Name: G. ruber pink, dtype: int64\n",
      "location    38\n",
      "Name: G. sacculifer, dtype: int64\n",
      "[35, 22, 0]\n",
      "location    30\n",
      "Name: G. scitula, dtype: int64\n",
      "[16, 4, 0]\n",
      "location    35\n",
      "Name: G. siphonifera, dtype: int64\n",
      "[26, 5, 0]\n",
      "location    43\n",
      "Name: G. truncatulinoides, dtype: int64\n",
      "[34, 44, 0]\n",
      "location    35\n",
      "Name: G. tumida, dtype: int64\n",
      "[28, 1, 0]\n",
      "location    19\n",
      "Name: G. ungulata, dtype: int64\n",
      "[15, 4, 0]\n",
      "location    21\n",
      "Name: N. acostaensis, dtype: int64\n",
      "[11, 5, 0]\n",
      "location    14\n",
      "Name: N. dutertrei, dtype: int64\n",
      "[11, 13, 0]\n",
      "location    25\n",
      "Name: N. humerosa, dtype: int64\n",
      "[16, 6, 0]\n",
      "location    5\n",
      "Name: O. universa, dtype: int64\n",
      "[3, 3, 0]\n",
      "location    35\n",
      "Name: P. obliquiloculata, dtype: int64\n",
      "[19, 9, 0]\n",
      "location    36\n",
      "Name: S. dehiscen, dtype: int64\n",
      "[29, 9, 0]\n"
     ]
    }
   ],
   "source": [
    "micro_f1, data_stuff = F1(model, dataloaders['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    true_positive  false_positive  total_per_species  precision    recall  \\\n",
      "0               0               1                 26   0.000000  0.000000   \n",
      "1               9               1                 21   0.900000  0.428571   \n",
      "2               0               0                  0        NaN       NaN   \n",
      "3              28              14                 35   0.666667  0.800000   \n",
      "4               0               0                  0        NaN       NaN   \n",
      "5              35              22                 38   0.614035  0.921053   \n",
      "6              16               4                 30   0.800000  0.533333   \n",
      "7              26               5                 35   0.838710  0.742857   \n",
      "8              34              44                 43   0.435897  0.790698   \n",
      "9              28               1                 35   0.965517  0.800000   \n",
      "10             15               4                 19   0.789474  0.789474   \n",
      "11             11               5                 21   0.687500  0.523810   \n",
      "12             11              13                 14   0.458333  0.785714   \n",
      "13             16               6                 25   0.727273  0.640000   \n",
      "14              3               3                  5   0.500000  0.600000   \n",
      "15             19               9                 35   0.678571  0.542857   \n",
      "16             29               9                 36   0.763158  0.805556   \n",
      "\n",
      "     F-score  \n",
      "0        NaN  \n",
      "1   0.580645  \n",
      "2        NaN  \n",
      "3   0.727273  \n",
      "4        NaN  \n",
      "5   0.736842  \n",
      "6   0.640000  \n",
      "7   0.787879  \n",
      "8   0.561983  \n",
      "9   0.875000  \n",
      "10  0.789474  \n",
      "11  0.594595  \n",
      "12  0.578947  \n",
      "13  0.680851  \n",
      "14  0.545455  \n",
      "15  0.603175  \n",
      "16  0.783784  \n"
     ]
    }
   ],
   "source": [
    "print(data_stuff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ft_kernel",
   "language": "python",
   "name": "ft_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
