{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file allows me to visualize the parameters in each model\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim, cuda\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 16) # resets finaly layer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=512, out_features=16, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "        AvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,532,008\n",
      "Non-trainable params: 157,504\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 107.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    if 128 in param.shape:\n",
    "        break\n",
    "    param.requires_grad = False\n",
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "print(len(list(model.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet34(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
      "             ReLU-21           [-1, 64, 56, 56]               0\n",
      "           Conv2d-22           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-23           [-1, 64, 56, 56]             128\n",
      "             ReLU-24           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-25           [-1, 64, 56, 56]               0\n",
      "           Conv2d-26          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-27          [-1, 128, 28, 28]             256\n",
      "             ReLU-28          [-1, 128, 28, 28]               0\n",
      "           Conv2d-29          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-30          [-1, 128, 28, 28]             256\n",
      "           Conv2d-31          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-36          [-1, 128, 28, 28]             256\n",
      "             ReLU-37          [-1, 128, 28, 28]               0\n",
      "           Conv2d-38          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-39          [-1, 128, 28, 28]             256\n",
      "             ReLU-40          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-41          [-1, 128, 28, 28]               0\n",
      "           Conv2d-42          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-43          [-1, 128, 28, 28]             256\n",
      "             ReLU-44          [-1, 128, 28, 28]               0\n",
      "           Conv2d-45          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-46          [-1, 128, 28, 28]             256\n",
      "             ReLU-47          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-48          [-1, 128, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-55          [-1, 128, 28, 28]               0\n",
      "           Conv2d-56          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-57          [-1, 256, 14, 14]             512\n",
      "             ReLU-58          [-1, 256, 14, 14]               0\n",
      "           Conv2d-59          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-60          [-1, 256, 14, 14]             512\n",
      "           Conv2d-61          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-62          [-1, 256, 14, 14]             512\n",
      "             ReLU-63          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-64          [-1, 256, 14, 14]               0\n",
      "           Conv2d-65          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-66          [-1, 256, 14, 14]             512\n",
      "             ReLU-67          [-1, 256, 14, 14]               0\n",
      "           Conv2d-68          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-69          [-1, 256, 14, 14]             512\n",
      "             ReLU-70          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-71          [-1, 256, 14, 14]               0\n",
      "           Conv2d-72          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-73          [-1, 256, 14, 14]             512\n",
      "             ReLU-74          [-1, 256, 14, 14]               0\n",
      "           Conv2d-75          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-76          [-1, 256, 14, 14]             512\n",
      "             ReLU-77          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-78          [-1, 256, 14, 14]               0\n",
      "           Conv2d-79          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-80          [-1, 256, 14, 14]             512\n",
      "             ReLU-81          [-1, 256, 14, 14]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-85          [-1, 256, 14, 14]               0\n",
      "           Conv2d-86          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-87          [-1, 256, 14, 14]             512\n",
      "             ReLU-88          [-1, 256, 14, 14]               0\n",
      "           Conv2d-89          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-90          [-1, 256, 14, 14]             512\n",
      "             ReLU-91          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-92          [-1, 256, 14, 14]               0\n",
      "           Conv2d-93          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-94          [-1, 256, 14, 14]             512\n",
      "             ReLU-95          [-1, 256, 14, 14]               0\n",
      "           Conv2d-96          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-97          [-1, 256, 14, 14]             512\n",
      "             ReLU-98          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-99          [-1, 256, 14, 14]               0\n",
      "          Conv2d-100            [-1, 512, 7, 7]       1,179,648\n",
      "     BatchNorm2d-101            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-102            [-1, 512, 7, 7]               0\n",
      "          Conv2d-103            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-104            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-105            [-1, 512, 7, 7]         131,072\n",
      "     BatchNorm2d-106            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-107            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-108            [-1, 512, 7, 7]               0\n",
      "          Conv2d-109            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-110            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-111            [-1, 512, 7, 7]               0\n",
      "          Conv2d-112            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-113            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-114            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-115            [-1, 512, 7, 7]               0\n",
      "          Conv2d-116            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-117            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-118            [-1, 512, 7, 7]               0\n",
      "          Conv2d-119            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-120            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-121            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-122            [-1, 512, 7, 7]               0\n",
      "       AvgPool2d-123            [-1, 512, 1, 1]               0\n",
      "          Linear-124                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 21,797,672\n",
      "Trainable params: 21,797,672\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 96.29\n",
      "Params size (MB): 83.15\n",
      "Estimated Total Size (MB): 180.01\n",
      "----------------------------------------------------------------\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3, 224, 224))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camelcars/Documents/ucl2/systemsEng/software_FT/venv/lib/python3.5/site-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /home/camelcars/.torch/models/densenet121-a639ec97.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "model = models.densenet121(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "       BatchNorm2d-5           [-1, 64, 56, 56]             128\n",
      "              ReLU-6           [-1, 64, 56, 56]               0\n",
      "            Conv2d-7          [-1, 128, 56, 56]           8,192\n",
      "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
      "              ReLU-9          [-1, 128, 56, 56]               0\n",
      "           Conv2d-10           [-1, 32, 56, 56]          36,864\n",
      "      BatchNorm2d-11           [-1, 96, 56, 56]             192\n",
      "             ReLU-12           [-1, 96, 56, 56]               0\n",
      "           Conv2d-13          [-1, 128, 56, 56]          12,288\n",
      "      BatchNorm2d-14          [-1, 128, 56, 56]             256\n",
      "             ReLU-15          [-1, 128, 56, 56]               0\n",
      "           Conv2d-16           [-1, 32, 56, 56]          36,864\n",
      "      BatchNorm2d-17          [-1, 128, 56, 56]             256\n",
      "             ReLU-18          [-1, 128, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 56, 56]          16,384\n",
      "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
      "             ReLU-21          [-1, 128, 56, 56]               0\n",
      "           Conv2d-22           [-1, 32, 56, 56]          36,864\n",
      "      BatchNorm2d-23          [-1, 160, 56, 56]             320\n",
      "             ReLU-24          [-1, 160, 56, 56]               0\n",
      "           Conv2d-25          [-1, 128, 56, 56]          20,480\n",
      "      BatchNorm2d-26          [-1, 128, 56, 56]             256\n",
      "             ReLU-27          [-1, 128, 56, 56]               0\n",
      "           Conv2d-28           [-1, 32, 56, 56]          36,864\n",
      "      BatchNorm2d-29          [-1, 192, 56, 56]             384\n",
      "             ReLU-30          [-1, 192, 56, 56]               0\n",
      "           Conv2d-31          [-1, 128, 56, 56]          24,576\n",
      "      BatchNorm2d-32          [-1, 128, 56, 56]             256\n",
      "             ReLU-33          [-1, 128, 56, 56]               0\n",
      "           Conv2d-34           [-1, 32, 56, 56]          36,864\n",
      "      BatchNorm2d-35          [-1, 224, 56, 56]             448\n",
      "             ReLU-36          [-1, 224, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          28,672\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40           [-1, 32, 56, 56]          36,864\n",
      "      BatchNorm2d-41          [-1, 256, 56, 56]             512\n",
      "             ReLU-42          [-1, 256, 56, 56]               0\n",
      "           Conv2d-43          [-1, 128, 56, 56]          32,768\n",
      "        AvgPool2d-44          [-1, 128, 28, 28]               0\n",
      "      BatchNorm2d-45          [-1, 128, 28, 28]             256\n",
      "             ReLU-46          [-1, 128, 28, 28]               0\n",
      "           Conv2d-47          [-1, 128, 28, 28]          16,384\n",
      "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
      "             ReLU-49          [-1, 128, 28, 28]               0\n",
      "           Conv2d-50           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-51          [-1, 160, 28, 28]             320\n",
      "             ReLU-52          [-1, 160, 28, 28]               0\n",
      "           Conv2d-53          [-1, 128, 28, 28]          20,480\n",
      "      BatchNorm2d-54          [-1, 128, 28, 28]             256\n",
      "             ReLU-55          [-1, 128, 28, 28]               0\n",
      "           Conv2d-56           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-57          [-1, 192, 28, 28]             384\n",
      "             ReLU-58          [-1, 192, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          24,576\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-63          [-1, 224, 28, 28]             448\n",
      "             ReLU-64          [-1, 224, 28, 28]               0\n",
      "           Conv2d-65          [-1, 128, 28, 28]          28,672\n",
      "      BatchNorm2d-66          [-1, 128, 28, 28]             256\n",
      "             ReLU-67          [-1, 128, 28, 28]               0\n",
      "           Conv2d-68           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-69          [-1, 256, 28, 28]             512\n",
      "             ReLU-70          [-1, 256, 28, 28]               0\n",
      "           Conv2d-71          [-1, 128, 28, 28]          32,768\n",
      "      BatchNorm2d-72          [-1, 128, 28, 28]             256\n",
      "             ReLU-73          [-1, 128, 28, 28]               0\n",
      "           Conv2d-74           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-75          [-1, 288, 28, 28]             576\n",
      "             ReLU-76          [-1, 288, 28, 28]               0\n",
      "           Conv2d-77          [-1, 128, 28, 28]          36,864\n",
      "      BatchNorm2d-78          [-1, 128, 28, 28]             256\n",
      "             ReLU-79          [-1, 128, 28, 28]               0\n",
      "           Conv2d-80           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-81          [-1, 320, 28, 28]             640\n",
      "             ReLU-82          [-1, 320, 28, 28]               0\n",
      "           Conv2d-83          [-1, 128, 28, 28]          40,960\n",
      "      BatchNorm2d-84          [-1, 128, 28, 28]             256\n",
      "             ReLU-85          [-1, 128, 28, 28]               0\n",
      "           Conv2d-86           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-87          [-1, 352, 28, 28]             704\n",
      "             ReLU-88          [-1, 352, 28, 28]               0\n",
      "           Conv2d-89          [-1, 128, 28, 28]          45,056\n",
      "      BatchNorm2d-90          [-1, 128, 28, 28]             256\n",
      "             ReLU-91          [-1, 128, 28, 28]               0\n",
      "           Conv2d-92           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-93          [-1, 384, 28, 28]             768\n",
      "             ReLU-94          [-1, 384, 28, 28]               0\n",
      "           Conv2d-95          [-1, 128, 28, 28]          49,152\n",
      "      BatchNorm2d-96          [-1, 128, 28, 28]             256\n",
      "             ReLU-97          [-1, 128, 28, 28]               0\n",
      "           Conv2d-98           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-99          [-1, 416, 28, 28]             832\n",
      "            ReLU-100          [-1, 416, 28, 28]               0\n",
      "          Conv2d-101          [-1, 128, 28, 28]          53,248\n",
      "     BatchNorm2d-102          [-1, 128, 28, 28]             256\n",
      "            ReLU-103          [-1, 128, 28, 28]               0\n",
      "          Conv2d-104           [-1, 32, 28, 28]          36,864\n",
      "     BatchNorm2d-105          [-1, 448, 28, 28]             896\n",
      "            ReLU-106          [-1, 448, 28, 28]               0\n",
      "          Conv2d-107          [-1, 128, 28, 28]          57,344\n",
      "     BatchNorm2d-108          [-1, 128, 28, 28]             256\n",
      "            ReLU-109          [-1, 128, 28, 28]               0\n",
      "          Conv2d-110           [-1, 32, 28, 28]          36,864\n",
      "     BatchNorm2d-111          [-1, 480, 28, 28]             960\n",
      "            ReLU-112          [-1, 480, 28, 28]               0\n",
      "          Conv2d-113          [-1, 128, 28, 28]          61,440\n",
      "     BatchNorm2d-114          [-1, 128, 28, 28]             256\n",
      "            ReLU-115          [-1, 128, 28, 28]               0\n",
      "          Conv2d-116           [-1, 32, 28, 28]          36,864\n",
      "     BatchNorm2d-117          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-118          [-1, 512, 28, 28]               0\n",
      "          Conv2d-119          [-1, 256, 28, 28]         131,072\n",
      "       AvgPool2d-120          [-1, 256, 14, 14]               0\n",
      "     BatchNorm2d-121          [-1, 256, 14, 14]             512\n",
      "            ReLU-122          [-1, 256, 14, 14]               0\n",
      "          Conv2d-123          [-1, 128, 14, 14]          32,768\n",
      "     BatchNorm2d-124          [-1, 128, 14, 14]             256\n",
      "            ReLU-125          [-1, 128, 14, 14]               0\n",
      "          Conv2d-126           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-127          [-1, 288, 14, 14]             576\n",
      "            ReLU-128          [-1, 288, 14, 14]               0\n",
      "          Conv2d-129          [-1, 128, 14, 14]          36,864\n",
      "     BatchNorm2d-130          [-1, 128, 14, 14]             256\n",
      "            ReLU-131          [-1, 128, 14, 14]               0\n",
      "          Conv2d-132           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-133          [-1, 320, 14, 14]             640\n",
      "            ReLU-134          [-1, 320, 14, 14]               0\n",
      "          Conv2d-135          [-1, 128, 14, 14]          40,960\n",
      "     BatchNorm2d-136          [-1, 128, 14, 14]             256\n",
      "            ReLU-137          [-1, 128, 14, 14]               0\n",
      "          Conv2d-138           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-139          [-1, 352, 14, 14]             704\n",
      "            ReLU-140          [-1, 352, 14, 14]               0\n",
      "          Conv2d-141          [-1, 128, 14, 14]          45,056\n",
      "     BatchNorm2d-142          [-1, 128, 14, 14]             256\n",
      "            ReLU-143          [-1, 128, 14, 14]               0\n",
      "          Conv2d-144           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-145          [-1, 384, 14, 14]             768\n",
      "            ReLU-146          [-1, 384, 14, 14]               0\n",
      "          Conv2d-147          [-1, 128, 14, 14]          49,152\n",
      "     BatchNorm2d-148          [-1, 128, 14, 14]             256\n",
      "            ReLU-149          [-1, 128, 14, 14]               0\n",
      "          Conv2d-150           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-151          [-1, 416, 14, 14]             832\n",
      "            ReLU-152          [-1, 416, 14, 14]               0\n",
      "          Conv2d-153          [-1, 128, 14, 14]          53,248\n",
      "     BatchNorm2d-154          [-1, 128, 14, 14]             256\n",
      "            ReLU-155          [-1, 128, 14, 14]               0\n",
      "          Conv2d-156           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-157          [-1, 448, 14, 14]             896\n",
      "            ReLU-158          [-1, 448, 14, 14]               0\n",
      "          Conv2d-159          [-1, 128, 14, 14]          57,344\n",
      "     BatchNorm2d-160          [-1, 128, 14, 14]             256\n",
      "            ReLU-161          [-1, 128, 14, 14]               0\n",
      "          Conv2d-162           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-163          [-1, 480, 14, 14]             960\n",
      "            ReLU-164          [-1, 480, 14, 14]               0\n",
      "          Conv2d-165          [-1, 128, 14, 14]          61,440\n",
      "     BatchNorm2d-166          [-1, 128, 14, 14]             256\n",
      "            ReLU-167          [-1, 128, 14, 14]               0\n",
      "          Conv2d-168           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-169          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-170          [-1, 512, 14, 14]               0\n",
      "          Conv2d-171          [-1, 128, 14, 14]          65,536\n",
      "     BatchNorm2d-172          [-1, 128, 14, 14]             256\n",
      "            ReLU-173          [-1, 128, 14, 14]               0\n",
      "          Conv2d-174           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-175          [-1, 544, 14, 14]           1,088\n",
      "            ReLU-176          [-1, 544, 14, 14]               0\n",
      "          Conv2d-177          [-1, 128, 14, 14]          69,632\n",
      "     BatchNorm2d-178          [-1, 128, 14, 14]             256\n",
      "            ReLU-179          [-1, 128, 14, 14]               0\n",
      "          Conv2d-180           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-181          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-182          [-1, 576, 14, 14]               0\n",
      "          Conv2d-183          [-1, 128, 14, 14]          73,728\n",
      "     BatchNorm2d-184          [-1, 128, 14, 14]             256\n",
      "            ReLU-185          [-1, 128, 14, 14]               0\n",
      "          Conv2d-186           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-187          [-1, 608, 14, 14]           1,216\n",
      "            ReLU-188          [-1, 608, 14, 14]               0\n",
      "          Conv2d-189          [-1, 128, 14, 14]          77,824\n",
      "     BatchNorm2d-190          [-1, 128, 14, 14]             256\n",
      "            ReLU-191          [-1, 128, 14, 14]               0\n",
      "          Conv2d-192           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-193          [-1, 640, 14, 14]           1,280\n",
      "            ReLU-194          [-1, 640, 14, 14]               0\n",
      "          Conv2d-195          [-1, 128, 14, 14]          81,920\n",
      "     BatchNorm2d-196          [-1, 128, 14, 14]             256\n",
      "            ReLU-197          [-1, 128, 14, 14]               0\n",
      "          Conv2d-198           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-199          [-1, 672, 14, 14]           1,344\n",
      "            ReLU-200          [-1, 672, 14, 14]               0\n",
      "          Conv2d-201          [-1, 128, 14, 14]          86,016\n",
      "     BatchNorm2d-202          [-1, 128, 14, 14]             256\n",
      "            ReLU-203          [-1, 128, 14, 14]               0\n",
      "          Conv2d-204           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-205          [-1, 704, 14, 14]           1,408\n",
      "            ReLU-206          [-1, 704, 14, 14]               0\n",
      "          Conv2d-207          [-1, 128, 14, 14]          90,112\n",
      "     BatchNorm2d-208          [-1, 128, 14, 14]             256\n",
      "            ReLU-209          [-1, 128, 14, 14]               0\n",
      "          Conv2d-210           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-211          [-1, 736, 14, 14]           1,472\n",
      "            ReLU-212          [-1, 736, 14, 14]               0\n",
      "          Conv2d-213          [-1, 128, 14, 14]          94,208\n",
      "     BatchNorm2d-214          [-1, 128, 14, 14]             256\n",
      "            ReLU-215          [-1, 128, 14, 14]               0\n",
      "          Conv2d-216           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-217          [-1, 768, 14, 14]           1,536\n",
      "            ReLU-218          [-1, 768, 14, 14]               0\n",
      "          Conv2d-219          [-1, 128, 14, 14]          98,304\n",
      "     BatchNorm2d-220          [-1, 128, 14, 14]             256\n",
      "            ReLU-221          [-1, 128, 14, 14]               0\n",
      "          Conv2d-222           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-223          [-1, 800, 14, 14]           1,600\n",
      "            ReLU-224          [-1, 800, 14, 14]               0\n",
      "          Conv2d-225          [-1, 128, 14, 14]         102,400\n",
      "     BatchNorm2d-226          [-1, 128, 14, 14]             256\n",
      "            ReLU-227          [-1, 128, 14, 14]               0\n",
      "          Conv2d-228           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-229          [-1, 832, 14, 14]           1,664\n",
      "            ReLU-230          [-1, 832, 14, 14]               0\n",
      "          Conv2d-231          [-1, 128, 14, 14]         106,496\n",
      "     BatchNorm2d-232          [-1, 128, 14, 14]             256\n",
      "            ReLU-233          [-1, 128, 14, 14]               0\n",
      "          Conv2d-234           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-235          [-1, 864, 14, 14]           1,728\n",
      "            ReLU-236          [-1, 864, 14, 14]               0\n",
      "          Conv2d-237          [-1, 128, 14, 14]         110,592\n",
      "     BatchNorm2d-238          [-1, 128, 14, 14]             256\n",
      "            ReLU-239          [-1, 128, 14, 14]               0\n",
      "          Conv2d-240           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-241          [-1, 896, 14, 14]           1,792\n",
      "            ReLU-242          [-1, 896, 14, 14]               0\n",
      "          Conv2d-243          [-1, 128, 14, 14]         114,688\n",
      "     BatchNorm2d-244          [-1, 128, 14, 14]             256\n",
      "            ReLU-245          [-1, 128, 14, 14]               0\n",
      "          Conv2d-246           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-247          [-1, 928, 14, 14]           1,856\n",
      "            ReLU-248          [-1, 928, 14, 14]               0\n",
      "          Conv2d-249          [-1, 128, 14, 14]         118,784\n",
      "     BatchNorm2d-250          [-1, 128, 14, 14]             256\n",
      "            ReLU-251          [-1, 128, 14, 14]               0\n",
      "          Conv2d-252           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-253          [-1, 960, 14, 14]           1,920\n",
      "            ReLU-254          [-1, 960, 14, 14]               0\n",
      "          Conv2d-255          [-1, 128, 14, 14]         122,880\n",
      "     BatchNorm2d-256          [-1, 128, 14, 14]             256\n",
      "            ReLU-257          [-1, 128, 14, 14]               0\n",
      "          Conv2d-258           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-259          [-1, 992, 14, 14]           1,984\n",
      "            ReLU-260          [-1, 992, 14, 14]               0\n",
      "          Conv2d-261          [-1, 128, 14, 14]         126,976\n",
      "     BatchNorm2d-262          [-1, 128, 14, 14]             256\n",
      "            ReLU-263          [-1, 128, 14, 14]               0\n",
      "          Conv2d-264           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-265         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-266         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-267          [-1, 512, 14, 14]         524,288\n",
      "       AvgPool2d-268            [-1, 512, 7, 7]               0\n",
      "     BatchNorm2d-269            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-270            [-1, 512, 7, 7]               0\n",
      "          Conv2d-271            [-1, 128, 7, 7]          65,536\n",
      "     BatchNorm2d-272            [-1, 128, 7, 7]             256\n",
      "            ReLU-273            [-1, 128, 7, 7]               0\n",
      "          Conv2d-274             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-275            [-1, 544, 7, 7]           1,088\n",
      "            ReLU-276            [-1, 544, 7, 7]               0\n",
      "          Conv2d-277            [-1, 128, 7, 7]          69,632\n",
      "     BatchNorm2d-278            [-1, 128, 7, 7]             256\n",
      "            ReLU-279            [-1, 128, 7, 7]               0\n",
      "          Conv2d-280             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-281            [-1, 576, 7, 7]           1,152\n",
      "            ReLU-282            [-1, 576, 7, 7]               0\n",
      "          Conv2d-283            [-1, 128, 7, 7]          73,728\n",
      "     BatchNorm2d-284            [-1, 128, 7, 7]             256\n",
      "            ReLU-285            [-1, 128, 7, 7]               0\n",
      "          Conv2d-286             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-287            [-1, 608, 7, 7]           1,216\n",
      "            ReLU-288            [-1, 608, 7, 7]               0\n",
      "          Conv2d-289            [-1, 128, 7, 7]          77,824\n",
      "     BatchNorm2d-290            [-1, 128, 7, 7]             256\n",
      "            ReLU-291            [-1, 128, 7, 7]               0\n",
      "          Conv2d-292             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-293            [-1, 640, 7, 7]           1,280\n",
      "            ReLU-294            [-1, 640, 7, 7]               0\n",
      "          Conv2d-295            [-1, 128, 7, 7]          81,920\n",
      "     BatchNorm2d-296            [-1, 128, 7, 7]             256\n",
      "            ReLU-297            [-1, 128, 7, 7]               0\n",
      "          Conv2d-298             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-299            [-1, 672, 7, 7]           1,344\n",
      "            ReLU-300            [-1, 672, 7, 7]               0\n",
      "          Conv2d-301            [-1, 128, 7, 7]          86,016\n",
      "     BatchNorm2d-302            [-1, 128, 7, 7]             256\n",
      "            ReLU-303            [-1, 128, 7, 7]               0\n",
      "          Conv2d-304             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-305            [-1, 704, 7, 7]           1,408\n",
      "            ReLU-306            [-1, 704, 7, 7]               0\n",
      "          Conv2d-307            [-1, 128, 7, 7]          90,112\n",
      "     BatchNorm2d-308            [-1, 128, 7, 7]             256\n",
      "            ReLU-309            [-1, 128, 7, 7]               0\n",
      "          Conv2d-310             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-311            [-1, 736, 7, 7]           1,472\n",
      "            ReLU-312            [-1, 736, 7, 7]               0\n",
      "          Conv2d-313            [-1, 128, 7, 7]          94,208\n",
      "     BatchNorm2d-314            [-1, 128, 7, 7]             256\n",
      "            ReLU-315            [-1, 128, 7, 7]               0\n",
      "          Conv2d-316             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-317            [-1, 768, 7, 7]           1,536\n",
      "            ReLU-318            [-1, 768, 7, 7]               0\n",
      "          Conv2d-319            [-1, 128, 7, 7]          98,304\n",
      "     BatchNorm2d-320            [-1, 128, 7, 7]             256\n",
      "            ReLU-321            [-1, 128, 7, 7]               0\n",
      "          Conv2d-322             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-323            [-1, 800, 7, 7]           1,600\n",
      "            ReLU-324            [-1, 800, 7, 7]               0\n",
      "          Conv2d-325            [-1, 128, 7, 7]         102,400\n",
      "     BatchNorm2d-326            [-1, 128, 7, 7]             256\n",
      "            ReLU-327            [-1, 128, 7, 7]               0\n",
      "          Conv2d-328             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-329            [-1, 832, 7, 7]           1,664\n",
      "            ReLU-330            [-1, 832, 7, 7]               0\n",
      "          Conv2d-331            [-1, 128, 7, 7]         106,496\n",
      "     BatchNorm2d-332            [-1, 128, 7, 7]             256\n",
      "            ReLU-333            [-1, 128, 7, 7]               0\n",
      "          Conv2d-334             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-335            [-1, 864, 7, 7]           1,728\n",
      "            ReLU-336            [-1, 864, 7, 7]               0\n",
      "          Conv2d-337            [-1, 128, 7, 7]         110,592\n",
      "     BatchNorm2d-338            [-1, 128, 7, 7]             256\n",
      "            ReLU-339            [-1, 128, 7, 7]               0\n",
      "          Conv2d-340             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-341            [-1, 896, 7, 7]           1,792\n",
      "            ReLU-342            [-1, 896, 7, 7]               0\n",
      "          Conv2d-343            [-1, 128, 7, 7]         114,688\n",
      "     BatchNorm2d-344            [-1, 128, 7, 7]             256\n",
      "            ReLU-345            [-1, 128, 7, 7]               0\n",
      "          Conv2d-346             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-347            [-1, 928, 7, 7]           1,856\n",
      "            ReLU-348            [-1, 928, 7, 7]               0\n",
      "          Conv2d-349            [-1, 128, 7, 7]         118,784\n",
      "     BatchNorm2d-350            [-1, 128, 7, 7]             256\n",
      "            ReLU-351            [-1, 128, 7, 7]               0\n",
      "          Conv2d-352             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-353            [-1, 960, 7, 7]           1,920\n",
      "            ReLU-354            [-1, 960, 7, 7]               0\n",
      "          Conv2d-355            [-1, 128, 7, 7]         122,880\n",
      "     BatchNorm2d-356            [-1, 128, 7, 7]             256\n",
      "            ReLU-357            [-1, 128, 7, 7]               0\n",
      "          Conv2d-358             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-359            [-1, 992, 7, 7]           1,984\n",
      "            ReLU-360            [-1, 992, 7, 7]               0\n",
      "          Conv2d-361            [-1, 128, 7, 7]         126,976\n",
      "     BatchNorm2d-362            [-1, 128, 7, 7]             256\n",
      "            ReLU-363            [-1, 128, 7, 7]               0\n",
      "          Conv2d-364             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-365           [-1, 1024, 7, 7]           2,048\n",
      "          Linear-366                 [-1, 1000]       1,025,000\n",
      "================================================================\n",
      "Total params: 7,978,856\n",
      "Trainable params: 7,978,856\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 294.20\n",
      "Params size (MB): 30.44\n",
      "Estimated Total Size (MB): 325.21\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3, 224, 224))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ft_kernel",
   "language": "python",
   "name": "ft_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
